{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload on file change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.yolov8 import *\n",
    "from src.yoloTrain import *\n",
    "from src.yoloDataset import *\n",
    "from src.yoloLoss import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded or caches\n",
      "File unziped\n",
      "Dataset je uspesno organizovan\n",
      "Finished dataset customization\n"
     ]
    }
   ],
   "source": [
    "from src.datasetSetup import srediDataset\n",
    "srediDataset(\"datasetoviraw\", \"datasetyolo.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_yolo = nn.Sequential(\n",
    "    nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2) \n",
    ")\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    images = list(images)\n",
    "    target_tensors = []\n",
    "    \n",
    "    for target in targets:\n",
    "        xx = target[0][:,:,0,:]\n",
    "        boxes = torch.tensor(xx, dtype=torch.float32)\n",
    "        labels = torch.tensor(target[1], dtype=torch.int64)\n",
    "        target_tensor = torch.cat((boxes, labels), dim=2)\n",
    "        target_tensors.append(target_tensor)\n",
    "    \n",
    "    target_tensors = torch.stack(target_tensors)   \n",
    "\n",
    "    return images, target_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = 'datasetoviraw/datasetyolo.zip_unzip/train/images'\n",
    "train_labels_dir = 'datasetoviraw/datasetyolo.zip_unzip/train/labels'\n",
    "\n",
    "\n",
    "train_dataset = YoloV8Dataset(train_img_dir, train_labels_dir, transform=transform_yolo)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_yolo, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lanal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lanal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv8(features=features_yolo)\n",
    "optimizer = optim.Adam(model.fc_layers.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size_yolo = 7  \n",
    "num_bboxes_yolo = 1 \n",
    "num_classes_yolo = 4 \n",
    "lambda_coord = 5.0\n",
    "lambda_noobj = 0.5\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.resnet18(pretrained=True)\n",
    "backbone = nn.Sequential(*list(backbone.children())[:-2]) \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "yolo_loss = YOLOv8Loss(feature_size=7, num_bboxes=1, num_classes=4, lambda_box=1.0, lambda_cls=1.0, lambda_df=1.0, phi=0.0005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch:   0%|          | 0/77 [00:00<?, ?it/s]C:\\Users\\lanal\\AppData\\Local\\Temp\\ipykernel_2876\\1619369655.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes = torch.tensor(xx, dtype=torch.float32)\n",
      "C:\\Users\\lanal\\AppData\\Local\\Temp\\ipykernel_2876\\1619369655.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(target[1], dtype=torch.int64)\n",
      "Training Epoch: 100%|██████████| 77/77 [01:08<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 85.7276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 77.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:05<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 69.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:11<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 64.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:06<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 55.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:06<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 51.6307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:06<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 45.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 39.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:08<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 34.8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch: 100%|██████████| 77/77 [01:10<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 29.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = YOLOv8Loss(feature_size=7, num_bboxes=1, num_classes=4, lambda_box=1.0, lambda_cls=1.0, lambda_df=1.0, phi=0.0005)\n",
    "\n",
    "for epoch in range(num_epochs_yolo):\n",
    "    epoch_loss = train(model, optimizer, train_loader, device, criterion)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs_yolo}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'yolov8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/dataset_yolo8/images/val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m label_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/dataset_yolo8/labels/val\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# List all images\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m image_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Plot a few example images\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/dataset_yolo8/images/val'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def load_image_and_labels(image_path, label_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    labels = []\n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                labels.append([float(x) for x in line.strip().split()])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading labels from {label_path}: {e}\")\n",
    "    \n",
    "    return image, labels\n",
    "\n",
    "def plot_image_with_bboxes(image, labels, class_names):\n",
    "    if image is None or labels is None:\n",
    "        print(\"No image or labels to display.\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    img_width, img_height = image.size\n",
    "    for label in labels:\n",
    "        if len(label) != 5:\n",
    "            print(f\"Invalid label format: {label}\")\n",
    "            continue\n",
    "        \n",
    "        class_id, x_center, y_center, width, height = label\n",
    "        x_center *= img_width\n",
    "        y_center *= img_height\n",
    "        width *= img_width\n",
    "        height *= img_height\n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x_min, y_min, class_names[int(class_id)], color='white', verticalalignment='top', bbox={'color': 'red', 'pad': 0})\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Class names for the dataset (modify as needed)\n",
    "class_names = [\"player\", \"referee\", \"goalkeeper\", \"ball\"]\n",
    "\n",
    "# Example usage:\n",
    "image_dir = \"datasetoviraw/datasetyolo.zip_unzip/wtest/images\"  # Update the path\n",
    "label_dir = \"datasetoviraw/datasetyolo.zip_unzip/wtest/labels\"  # Update the path\n",
    "\n",
    "# List all images\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Check if image_files is empty\n",
    "if not image_files:\n",
    "    print(f\"No images found in directory: {image_dir}\")\n",
    "\n",
    "# Plot a few example images\n",
    "for image_file in image_files[:5]:  # Change the number of images to plot\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    label_path = os.path.join(label_dir, image_file.replace('.jpg', '.txt'))\n",
    "    \n",
    "    image, labels = load_image_and_labels(image_path, label_path)\n",
    "    if image and labels:\n",
    "        plot_image_with_bboxes(image, labels, class_names)\n",
    "    else:\n",
    "        print(f\"Skipping {image_file} due to loading issues.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
